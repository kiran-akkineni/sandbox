import pandas as pd
# import spacy
# nlp = spacy.load('en')
import textacy

### read input file as csv
data_df = pd.read_csv(full_path_utf8,
                      names = ['Likes', 'Dislikes'],
                      skiprows = 3, usecols = [178,179]
                     )
# data_df.head()

# splitting main dataset into separate likes and dislikes datasets
likes_df = pd.DataFrame(data_df['Likes']).rename(index=str, columns={"Likes": "Comments"})

# counts of comments in likes
likes_count = likes_df['Comments'].count()
print('Count of likes: ' + str(likes_count))

# start topic modeling process by converting the likes dataframe to a list of docs, then to a corpus
docs_base = likes_df.values.tolist()
docs_list = [str(x) for x in docs_base]
corpus = textacy.Corpus('en', texts=docs_list)
# corpus

# initialize vectorizer
vectorizer = textacy.Vectorizer(
    min_df=2, 
    max_df=0.9,
    tf_type='linear', 
    apply_idf=True, 
    idf_type='smooth')

# vectorizer

# create the matrix (it should be using tfidf given vectorizer parameters)
doc_term_matrix = vectorizer.fit_transform(
    doc.to_terms_list(
        ngrams=3, 
        named_entities=False, 
        as_strings=True)
    for doc in corpus
)
# print(repr(doc_term_matrix))

#  build topic model, and print out results
model = textacy.TopicModel('nmf', n_topics=10)
model.fit(doc_term_matrix)
doc_topic_matrix = model.transform(doc_term_matrix)
# doc_topic_matrix.shape

for topic_idx, top_terms in model.top_topic_terms(
    vectorizer.id_to_term, 
    top_n=10):
    print('topic', topic_idx, ':', '   '.join(top_terms))
    
    
